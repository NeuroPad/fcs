# FCS Specification – Version 3.4 (External Failures + Tracked Ideas)

## Overview

Fluid Cognitive Scaffolding (FCS) is a persistent, voice-based cognitive system that remembers what the user says and uses that memory to help them think better. It offers real continuity, grounded responses, contradiction awareness, external reference integration, and real-time traceability. This document defines the functional scope and behavioral expectations for the MVP.

---

## Interaction Mode

- **Input**: Voice (STT) and user-submitted text
- **Output**: Voice (TTS), generated by LLM under graph-bound intent
- **Memory**: One persistent idea graph per session
- **Control**: Session is wiped clean only upon `reset()`

---

## Core Concepts

### Cognitive Objects (COs)

- Basic unit of idea representation
- Each CO includes:
    - `id`: Unique identifier (UUID)
    - `content`: Natural language text expressed or inferred
    - `type`: Enum: `idea`, `contradiction`, `reference`, `system_note`
    - `confidence`: Float [0.0 – 1.0] — how sure the system is this idea is currently valid
    - `salience`: Float — how central or reinforced this idea is within the session
    - `timestamp`: Time of creation or most recent reinforcement
    - `source`: One of `user`, `external`, or `system`
    - `flags`: Optional list, e.g. `tracked`, `contradiction`, `external`, `unverified`
    - `parent_ids`: List of `UUIDs` — COs this idea directly builds on
    - `child_ids`: List of `UUIDs` — COs derived from this idea
    - `match_history`: Optional list of CO IDs that have semantically reinforced this CO
    - `arbitration_score`: Optional — last known score from arbitration pass
    - `linked_refs`: Optional list of `CO.id` or source string, e.g., reference DOI or URL
    - `external_metadata`: Optional field for provenance or source abstract

### Note:

All COs are stored in a single in-memory graph with directed edges. Edges are also typed separately (e.g., `contradicts`, `reinforces`) but parent/child are always retained.

- Directed, acyclic, session-persistent
- Node types: `idea`, `contradiction`, `reference`, `system`
- Edges: `supports`, `contradicts`, `extends`, `reframes`

### Tracked Ideas

- Users or the system may mark COs as `tracked`
- These COs are monitored for future reinforcement, contradiction, or extension
- If match occurs, FCS may say:
    
    > “You’ve said that a few different ways. Want me to keep track of that going forward?”
    > 
- Matching increases salience and logs in metadata

---

## Contradiction Handling

- When a new CO conflicts sharply with a prior one, system generates a `type: contradiction` CO
- No destructive resolution occurs unless user prompts it

---

## LLM Behavior

FCS uses the LLM only to generate natural language output. The system determines *what* should be expressed, and the LLM determines *how* to say it.

---

### LLM Prompt Construction Pipeline

1. **Arbitration**
    - `run_arbitration(graph)` selects 1–3 high-relevance COs
    - Arbitration scores (confidence, salience, contradiction, recency) are retained for trace
2. **Intent Selection**
    - `route_intent()` sets the response goal:
        - `reflect`, `challenge`, `recognize_recurrence`, `reference`, or `stay_silent`
3. **Prompt Assembly**
    - Structured payload includes:

```json
{
  "intent": "challenge",
  "focus": "I work best under pressure.",
  "conflict": "But lately pressure makes me freeze.",
  "context": [
    "I want to be more stable",
    "Deadlines help, but I panic when they get too close"
  ],
  "metadata": {
    "confidence": 0.82,
    "reinforcement_count": 2,
    "source": "user"
  },
  "style": "spoken, natural, brief"
}

```

1. **Prompt Template Rendering**
    - Rendered prompt:
        
        > “You are assisting a user who is thinking aloud. Their current idea is:
        ‘I work best under pressure.’
        But a conflicting idea recently surfaced:
        ‘But lately pressure makes me freeze.’
        In the past, they’ve also said:
        ‘I want to be more stable’, ‘Deadlines help, but I panic when they get too close.’
        Your goal is to respond naturally and briefly in a way that invites reflection—not judgment.”
        > 
2. **LLM Output**
    - LLM generates response
    - Passed to TTS
    - Logged along with arbitration inputs, selected CO, and intent

FCS never asks the LLM to decide. It only asks it to speak *what FCS already knows is important.*

- All system output is generated via LLM
- **FCS determines intent**, scope, and content that should be rendered
- LLM is used only as a language layer—never for judgment or arbitration
- No tone imitation, affect simulation, or personality rendering

---

## When FCS Speaks (Expression Thresholds)

FCS responds *only* when:

- A **highly conflicting contradiction** emerges
- A **notably insightful shift or phrasing** occurs
- A **relevant external source** supports or challenges the current graph
- A **reinforced tracked idea** reaches salience threshold for attention

FCS remains silent when:

- Updates are structurally minor
- No tension or change in direction has been detected
- The user is exploring freely without contradiction or reinforcement shift

---

## External Source Access

### Purpose:

Enable FCS to enrich user thinking with relevant, non-invented outside data

### Process:

- User consents → `external_search(query)` is called
- FCS uses vetted domains: `nih.gov`, `pubmed.ncbi.nlm.nih.gov`, `arxiv.org`, `scholar.google.com`, etc.
- Preference for open-access sources; abstracts used if full text is unavailable
- If only paywalled, FCS says:
    
    > “I found something, but the full article isn’t publicly available. I can summarize the abstract if you like.”
    > 

### External Process Failure Handling

- If external source returns no result, fails, or times out:
    
    > “That source didn’t respond. Want to rephrase or keep going?”
    > 
- No hallucinated fallback content may be generated
- Query + failure reason is logged to trace for review

### Output:

- Response is parsed → `parse_external_to_CO()`
- Output COs are labeled: `type=reference`, `source=external`, `confidence=0.3`, `flag=unverified`
- User can accept, discard, or track those ideas

### Post-MVP:

- Upload and parsing of user-accessed full-text articles

---

## Reset Protocol

- `reset()` removes:
    - CO graph
    - Contradiction state
    - Arbitration metadata
    - Session log and trace

---

## Traceability (OpenTelemetry)

- Instrument:
    - `parse_input_to_CO()`
    - `evaluate_contradictions()`
    - `run_arbitration()`
    - `generate_response()`
    - `external_search()`
    - `parse_external_to_CO()`
- Trace metadata includes:
    - CO IDs, salience levels, contradiction count
    - Arbitration decisions
    - External source info (query string, domain, user consent)
    - External search failures (code, timeout, no match)

Traces allow for full reconstruction of the system’s reasoning.

---

## Voice Delivery via Vapi (Dev Context Only)

### Purpose

To allow real-time, low-latency bidirectional voice delivery in a development environment, FCS integrates with Vapi’s cloud-based voice SDK. If the FCS stack is running on a local machine or private dev server, an HTTP tunnel such as `ngrok` is required to expose a public endpoint to Vapi.

### Requirements

- Your local LLM response and TTS routing must be accessible to Vapi's voice agent via HTTPS
- You must maintain a public-facing webhook URL to receive:
    - Transcribed voice input (STT)
    - Timing/cue events (e.g., end of user speech)
    - Output triggers to deliver TTS playback

### Configuration Steps

1. Launch your FCS server locally (e.g., `http://localhost:3000`)
2. Create a secure tunnel to this port using:

```
ngrok http 3000
```

1. Copy the ngrok HTTPS URL (e.g., `https://abc123.ngrok.io`)
2. Register this as your voice webhook in the Vapi dashboard or developer config:

```
{
  "voice_agent_url": "https://abc123.ngrok.io/voice"
}
```

### Notes

- This is for **demo/testing purposes only** and should not be relied upon in production.
- Once deployed, the FCS backend should use a secured, persistent domain or cloud function endpoint
- All Vapi-triggered events must route through an internal intent dispatcher that links the voice cue to:
    - `parse_input_to_CO()`
    - `run_arbitration()`
    - `generate_prompt()` → `LLM` → `TTS`

---

## MVP Deliverables

- Persistent idea graph
- Spoken user input → tracked COs
- Contradiction detection and CO generation
- Arbitration and intent selection
- LLM → natural output under cognitive constraint
- One working external search cycle (from voice → query → reference COs)
- Reset function
- Full traceability via OpenTelemetry
- Safe failure handling for external search

---

FCS is not a scripted interface. This is an architecture for helping people think—real memory, real support, and real presence.